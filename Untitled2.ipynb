{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a65c944f-b9f2-4929-a309-19ad38c36817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in the zip: ['Apple_DB.csv', 'Data for Training - Apple DB - Accumulated Statement.csv']\n",
      "   Year        Date  Quarter  NetSales_Products  NetSales_Services  \\\n",
      "0  2023  09/01/2023        4              67184              22314   \n",
      "1  2023  06/01/2023        3              60584              21213   \n",
      "2  2023  04/01/2023        2              73929              20907   \n",
      "3  2022  12/01/2022        1              96388              20766   \n",
      "4  2022  09/01/2022        4              70958              19188   \n",
      "\n",
      "   NetSales_Total  COG_Products  COG_Services  COG_Total  Gross_margin  ...  \\\n",
      "0           89498         42586          6485      49071         40427  ...   \n",
      "1           81797         39136          6248      45384         36413  ...   \n",
      "2           94836         46795          6065      52860         41976  ...   \n",
      "3          117154         60765          6057      66822         50332  ...   \n",
      "4           90146         46387          5664      52051         38095  ...   \n",
      "\n",
      "   LiabilitiesNC_Term_debt  LiabilitiesNC_Other  LiabilitiesNC_Total  \\\n",
      "0                    95281                49848               145129   \n",
      "1                    98071                51730               149801   \n",
      "2                    97041                52886               149927   \n",
      "3                    99627                53107               152734   \n",
      "4                    98959                49142               148101   \n",
      "\n",
      "   Liabilities_Total  Shareholders_Equity_outstanding_respectively  \\\n",
      "0             290437                                         73812   \n",
      "1             274764                                         70667   \n",
      "2             270002                                         69568   \n",
      "3             290020                                         66399   \n",
      "4             302083                                         64849   \n",
      "\n",
      "   Retained_earnings  Accumulated_other_comprehensive_income  \\\n",
      "0               -214                                  -11452   \n",
      "1               1408                                  -11801   \n",
      "2               4336                                  -11746   \n",
      "3               3240                                  -12912   \n",
      "4              -3068                                  -11109   \n",
      "\n",
      "   Shareholders_Equity_Total  Total_liabilities_and_shareholders_equity  \\\n",
      "0                      62146                                     352583   \n",
      "1                      60274                                     335038   \n",
      "2                      62158                                     332160   \n",
      "3                      56727                                     346747   \n",
      "4                      50672                                     352755   \n",
      "\n",
      "   Stock_Price  \n",
      "0       338.11  \n",
      "1       335.92  \n",
      "2       307.26  \n",
      "3       247.81  \n",
      "4       232.13  \n",
      "\n",
      "[5 rows x 48 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 48 columns):\n",
      " #   Column                                        Non-Null Count  Dtype  \n",
      "---  ------                                        --------------  -----  \n",
      " 0   Year                                          20 non-null     int64  \n",
      " 1   Date                                          20 non-null     object \n",
      " 2   Quarter                                       20 non-null     int64  \n",
      " 3   NetSales_Products                             20 non-null     int64  \n",
      " 4   NetSales_Services                             20 non-null     int64  \n",
      " 5   NetSales_Total                                20 non-null     int64  \n",
      " 6   COG_Products                                  20 non-null     int64  \n",
      " 7   COG_Services                                  20 non-null     int64  \n",
      " 8   COG_Total                                     20 non-null     int64  \n",
      " 9   Gross_margin                                  20 non-null     int64  \n",
      " 10  OperatingExpase_RND                           20 non-null     int64  \n",
      " 11  OperatingExpase_SGA                           20 non-null     int64  \n",
      " 12  OperatingExpase_Total                         20 non-null     int64  \n",
      " 13  Operating_income                              20 non-null     int64  \n",
      " 14  Other_income_expanse                          20 non-null     int64  \n",
      " 15  Income_before_provision_for_income_taxes      20 non-null     int64  \n",
      " 16  Provision_for_income_taxes                    20 non-null     int64  \n",
      " 17  Net_income                                    20 non-null     int64  \n",
      " 18  Earnings_per_share_Basic                      20 non-null     float64\n",
      " 19  Earnings_per_share_Diluted                    20 non-null     float64\n",
      " 20  AssetsCurrent_Cash                            20 non-null     int64  \n",
      " 21  AssetsCurrent_Marketable_securities           20 non-null     int64  \n",
      " 22  AssetsCurrent_Accounts_receivable             20 non-null     int64  \n",
      " 23  AssetsCurrent_Inventories                     20 non-null     int64  \n",
      " 24  AssetsCurrent_non_trade_receivables           20 non-null     int64  \n",
      " 25  AssetsCurrent_Other                           20 non-null     int64  \n",
      " 26  AssetsCurrent_Total                           20 non-null     int64  \n",
      " 27  AssetsNC_Marketable_securities                20 non-null     int64  \n",
      " 28  AssetsNC_PPE                                  20 non-null     int64  \n",
      " 29  AssetsNC_Other                                20 non-null     int64  \n",
      " 30  AssetsNC_Total                                20 non-null     int64  \n",
      " 31  Assets_Total                                  20 non-null     int64  \n",
      " 32  LiabilitiesCurrent_Accounts payable           20 non-null     int64  \n",
      " 33  LiabilitiesCurrent_Other                      20 non-null     int64  \n",
      " 34  LiabilitiesCurrent_Deferred_revenue           20 non-null     int64  \n",
      " 35  LiabilitiesCurrent_Commercial_paper           20 non-null     int64  \n",
      " 36  LiabilitiesCurrent_Term_debt                  20 non-null     int64  \n",
      " 37  LiabilitiesCurrent_Total                      20 non-null     int64  \n",
      " 38  LiabilitiesNC_Term_debt                       20 non-null     int64  \n",
      " 39  LiabilitiesNC_Other                           20 non-null     int64  \n",
      " 40  LiabilitiesNC_Total                           20 non-null     int64  \n",
      " 41  Liabilities_Total                             20 non-null     int64  \n",
      " 42  Shareholders_Equity_outstanding_respectively  20 non-null     int64  \n",
      " 43  Retained_earnings                             20 non-null     int64  \n",
      " 44  Accumulated_other_comprehensive_income        20 non-null     int64  \n",
      " 45  Shareholders_Equity_Total                     20 non-null     int64  \n",
      " 46  Total_liabilities_and_shareholders_equity     20 non-null     int64  \n",
      " 47  Stock_Price                                   20 non-null     float64\n",
      "dtypes: float64(3), int64(44), object(1)\n",
      "memory usage: 7.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "zip_file_path = ('C:/Users/CC/Downloads/archive (1).zip')\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    \n",
    "    zip_ref.extractall('C:/Users/CC/Downloads/extracted_files')\n",
    "    \n",
    "    \n",
    "    print(\"Files in the zip:\", zip_ref.namelist())\n",
    "    \n",
    "    \n",
    "    csv_file_name = zip_ref.namelist()[0]  \n",
    "    \n",
    "    with zip_ref.open(csv_file_name) as csvfile:\n",
    "        df = pd.read_csv(csvfile)\n",
    "        \n",
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8923dd-9412-48e6-9cd2-99c23258bbe0",
   "metadata": {},
   "source": [
    "DATABASE A: This database is relevant because it may contain demographic, financial, or behavioral data that is highly relevant to analyzing how individuals interact with retirement systems. By assessing how people save, withdraw, and contribute to retirement funds, we can evaluate how well the two-pot system meets its objectives of providing financial relief in the short term and ensuring long-term financial security.\n",
    "This data can help assess whether the system achieves its objectives of providing financial relief while preserving retirement savings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2fb25453-fcd2-4242-88a5-4513801de27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in the zip: ['Employee.csv']\n",
      "   Education  JoiningYear       City  PaymentTier  Age  Gender EverBenched  \\\n",
      "0  Bachelors         2017  Bangalore            3   34    Male          No   \n",
      "1  Bachelors         2013       Pune            1   28  Female          No   \n",
      "2  Bachelors         2014  New Delhi            3   38  Female          No   \n",
      "3    Masters         2016  Bangalore            3   27    Male          No   \n",
      "4    Masters         2017       Pune            3   24    Male         Yes   \n",
      "\n",
      "   ExperienceInCurrentDomain  LeaveOrNot  \n",
      "0                          0           0  \n",
      "1                          3           1  \n",
      "2                          2           0  \n",
      "3                          5           1  \n",
      "4                          2           1  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4653 entries, 0 to 4652\n",
      "Data columns (total 9 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   Education                  4653 non-null   object\n",
      " 1   JoiningYear                4653 non-null   int64 \n",
      " 2   City                       4653 non-null   object\n",
      " 3   PaymentTier                4653 non-null   int64 \n",
      " 4   Age                        4653 non-null   int64 \n",
      " 5   Gender                     4653 non-null   object\n",
      " 6   EverBenched                4653 non-null   object\n",
      " 7   ExperienceInCurrentDomain  4653 non-null   int64 \n",
      " 8   LeaveOrNot                 4653 non-null   int64 \n",
      "dtypes: int64(5), object(4)\n",
      "memory usage: 327.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "zip_file_path = r'C:\\Users\\CC\\Downloads\\archive (3).zip'\n",
    "\n",
    "extracted_dir = r'C:\\Users\\CC\\Downloads\\extracted_files'\n",
    "os.makedirs(extracted_dir, exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "\n",
    "    zip_ref.extractall(extracted_dir)\n",
    "    \n",
    "    print(\"Files in the zip:\", zip_ref.namelist())\n",
    "    \n",
    "    csv_file_name = zip_ref.namelist()[0]\n",
    "    \n",
    "    with zip_ref.open(csv_file_name) as csvfile:\n",
    "        df = pd.read_csv(csvfile)\n",
    "\n",
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45676ca-ecb1-4c60-9a6a-bc155a9c9f5d",
   "metadata": {},
   "source": [
    "DATASET B :The relevance of the dataset to the Two-Pot Retirement System lies in its potential to provide valuable insights into individual behaviors, demographic factors, and economic influences that affect both immediate financial needs and long-term retirement savings. Analyzing this data can help improve the system's design, ensuring it meets its objectives of providing financial security for individuals during their retirement years while allowing them to address short-term financial challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2125893-633f-4094-9adc-fd28bf5db3de",
   "metadata": {},
   "source": [
    "Both the databases are relevant to the Two-Pots system's objectives. The 2 datasets were both found from https://www.kaggle.com/. If you want to access Kaddle you can use the link provided above, I may also advice you to have an account or create one to access more things on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d40ab7bb-11cf-482b-b065-8bfa4abd16f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Multiple files found in ZIP file. Only one file per ZIP: ['Apple_DB.csv', 'Data for Training - Apple DB - Accumulated Statement.csv']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:/Users/CC/Downloads/archive (1).zip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m missing_values \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/CC/Downloads/archive (3).zip\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:805\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    803\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZero files found in ZIP file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_buf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    804\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 805\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    806\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultiple files found in ZIP file. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    807\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly one file per ZIP: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    808\u001b[0m             )\n\u001b[0;32m    810\u001b[0m \u001b[38;5;66;03m# TAR Encoding\u001b[39;00m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m compression \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtar\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: Multiple files found in ZIP file. Only one file per ZIP: ['Apple_DB.csv', 'Data for Training - Apple DB - Accumulated Statement.csv']"
     ]
    }
   ],
   "source": [
    "df =pd.read_csv(r'C:/Users/CC/Downloads/archive (1).zip')\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "df =pd.read_csv(r'C:/Users/CC/Downloads/archive (3).zip')\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "df['numerical_column'].fillna(df['numerical_column'].mean(), inplace=True)\n",
    "df['categorical_column'].fillna(df['categorical_column'].mode()[0], inplace=True)\n",
    "\n",
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9457658a-a091-478b-be56-9216632b9ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'date_column' in df.columns:\n",
    "    df['year'] = pd.to_datetime(df['date_column']).dt.year\n",
    "    df['month'] = pd.to_datetime(df['date_column']).dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ee4a4e43-1016-499f-8796-94c8db82bfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year        Date  Quarter  NetSales_Products  NetSales_Services  \\\n",
      "0  2023  09/01/2023        4              67184              22314   \n",
      "1  2023  06/01/2023        3              60584              21213   \n",
      "2  2023  04/01/2023        2              73929              20907   \n",
      "3  2022  12/01/2022        1              96388              20766   \n",
      "4  2022  09/01/2022        4              70958              19188   \n",
      "\n",
      "   NetSales_Total  COG_Products  COG_Services  COG_Total  Gross_margin  ...  \\\n",
      "0           89498         42586          6485      49071         40427  ...   \n",
      "1           81797         39136          6248      45384         36413  ...   \n",
      "2           94836         46795          6065      52860         41976  ...   \n",
      "3          117154         60765          6057      66822         50332  ...   \n",
      "4           90146         46387          5664      52051         38095  ...   \n",
      "\n",
      "   LiabilitiesNC_Term_debt  LiabilitiesNC_Other  LiabilitiesNC_Total  \\\n",
      "0                    95281                49848               145129   \n",
      "1                    98071                51730               149801   \n",
      "2                    97041                52886               149927   \n",
      "3                    99627                53107               152734   \n",
      "4                    98959                49142               148101   \n",
      "\n",
      "   Liabilities_Total  Shareholders_Equity_outstanding_respectively  \\\n",
      "0             290437                                         73812   \n",
      "1             274764                                         70667   \n",
      "2             270002                                         69568   \n",
      "3             290020                                         66399   \n",
      "4             302083                                         64849   \n",
      "\n",
      "   Retained_earnings  Accumulated_other_comprehensive_income  \\\n",
      "0               -214                                  -11452   \n",
      "1               1408                                  -11801   \n",
      "2               4336                                  -11746   \n",
      "3               3240                                  -12912   \n",
      "4              -3068                                  -11109   \n",
      "\n",
      "   Shareholders_Equity_Total  Total_liabilities_and_shareholders_equity  \\\n",
      "0                      62146                                     352583   \n",
      "1                      60274                                     335038   \n",
      "2                      62158                                     332160   \n",
      "3                      56727                                     346747   \n",
      "4                      50672                                     352755   \n",
      "\n",
      "   Stock_Price  \n",
      "0       338.11  \n",
      "1       335.92  \n",
      "2       307.26  \n",
      "3       247.81  \n",
      "4       232.13  \n",
      "\n",
      "[5 rows x 48 columns]\n",
      "   Education  JoiningYear       City  PaymentTier  Age  Gender EverBenched  \\\n",
      "0  Bachelors         2017  Bangalore            3   34    Male          No   \n",
      "1  Bachelors         2013       Pune            1   28  Female          No   \n",
      "2  Bachelors         2014  New Delhi            3   38  Female          No   \n",
      "3    Masters         2016  Bangalore            3   27    Male          No   \n",
      "4    Masters         2017       Pune            3   24    Male         Yes   \n",
      "\n",
      "   ExperienceInCurrentDomain  LeaveOrNot  \n",
      "0                          0           0  \n",
      "1                          3           1  \n",
      "2                          2           0  \n",
      "3                          5           1  \n",
      "4                          2           1  \n"
     ]
    }
   ],
   "source": [
    "zip_file_path_1 = r'C:\\Users\\CC\\Downloads\\archive (1).zip'\n",
    "zip_file_path_2 = r'C:\\Users\\CC\\Downloads\\archive (3).zip'\n",
    "\n",
    "# \n",
    "def load_dataset(zip_file_path):\n",
    "    extracted_dir = r'C:\\Users\\CC\\Downloads\\extracted_files'\n",
    "    os.makedirs(extracted_dir, exist_ok=True)\n",
    "    \n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extracted_dir)\n",
    "        data_file_name = zip_ref.namelist()[0]  # Assuming first file is the target\n",
    "        df = pd.read_csv(os.path.join(extracted_dir, data_file_name))\n",
    "    \n",
    "    return df \n",
    "    \n",
    "df1 = load_dataset(zip_file_path_1)\n",
    "df2 = load_dataset(zip_file_path_2)\n",
    "\n",
    "# Inspect the data\n",
    "print(df1.head())\n",
    "print(df2.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e72ad77b-af01-436f-96c4-645b91beb459",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['date_column'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12164\\4252460176.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'date_column'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_monthly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_monthly\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'locked_pot'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Locked Pot Savings'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'blue'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[0;32m   6105\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfound\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6106\u001b[0m                         \u001b[0mmissing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6108\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6109\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33mf\"\u001b[0m\u001b[1;33mNone of \u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mmissing\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m are in the columns\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6111\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6112\u001b[0m             \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of ['date_column'] are in the columns\""
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df = read_csv(r'')\n",
    "\n",
    "zip_file_path = 'C:/Users/CC/Downloads/archive (1).zip'\n",
    "\n",
    "# Step 2: Open the ZIP file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as z:\n",
    "    # List all the files in the ZIP\n",
    "    z.printdir()\n",
    "    \n",
    "    # Step 3: Extract the specific CSV file you need\n",
    "    z.extract('Apple_DB.csv', path='extracted_data')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df_monthly.index, df_monthly['locked_pot'], label='Locked Pot Savings', color='blue')\n",
    "plt.title('Historical Growth of Locked Pot Savings')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Amount')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f78d762a-6759-4d9f-9a82-555c8f427099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4653, 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(571, 59)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (df.shape)\n",
    "(571, 59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0f135825-f8c5-40dc-83b9-c9e19ad111a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'statsmodels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtsa\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marima\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ARIMA\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraphics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtsaplots\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_acf, plot_pacf\n\u001b[0;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/CC/Downloads/archive (1).zip\u001b[39m\u001b[38;5;124m'\u001b[39m) \n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'statsmodels'"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "df = pd.read_csv(r'C:/Users/CC/Downloads/archive (1).zip') \n",
    "\n",
    "print(df.head())\n",
    "\n",
    "#Preprocess the Data\n",
    "df['date_column'] = pd.to_datetime(df['date_column'])  # Adjust 'date_column' to your actual date column name\n",
    "\n",
    "df.set_index('date_column', inplace=True)\n",
    "\n",
    "df_monthly = df.resample('M').sum()  # Adjust if you need a different aggregation method\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df_monthly['locked_pot'], label='Locked Pot Savings', color='blue')\n",
    "plt.title('Historical Growth of Locked Pot Savings')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Savings Amount')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# ARIMA Model\n",
    "model = ARIMA(df_monthly['locked_pot'], order=(1, 1, 1))\n",
    "model_fit = model.fit()\n",
    "\n",
    "print(model_fit.summary())\n",
    "\n",
    "forecast = model_fit.forecast(steps=12)\n",
    "forecast_index = pd.date_range(start=df_monthly.index[-1] + pd.DateOffset(1), periods=12, freq='M')\n",
    "\n",
    "forecast_df = pd.DataFrame(forecast, index=forecast_index, columns=['Forecasted Locked Pot Savings'])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df_monthly['locked_pot'], label='Historical Locked Pot Savings', color='blue')\n",
    "plt.plot(forecast_df, label='Forecasted Locked Pot Savings', color='orange', linestyle='--')\n",
    "plt.title('Historical and Forecasted Growth of Locked Pot Savings')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Savings Amount')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaa6807-ca4e-4e05-8aee-4467ab4f36ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "caceba28-d6b2-4d23-ba7a-ef46813a9be3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fbprophet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfbprophet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Prophet\n\u001b[0;32m      3\u001b[0m df_prophet \u001b[38;5;241m=\u001b[39m df_monthly\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m      4\u001b[0m df_prophet\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mds\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Rename columns to fit Prophet requirements\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fbprophet'"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67ea20a-0a4d-49af-9ac6-dc624d532bd6",
   "metadata": {},
   "source": [
    "NATURAL LANGUAGE PROCESSING: It is an interaction between computers and humans through natural language.Sentimental Analysis is part of Natural Language Processing (NLP), where text data such as employee feedback is analyzed to understand the underlying sentiment. \n",
    "\n",
    "The feedback reflects a generally positive experience with the team but also highlights a concern regarding workload, suggesting areas for potential improvement. This categorization can provide valuable insights into employee satisfaction, help identify areas for improvement, and guide decision-making within organizations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
